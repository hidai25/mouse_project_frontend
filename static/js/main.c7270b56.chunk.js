(this.webpackJsonpmouse_project_front_end=this.webpackJsonpmouse_project_front_end||[]).push([[0],{237:function(e,t,a){e.exports=a.p+"static/media/hidai.3326f7a9.jpeg"},238:function(e,t,a){e.exports=a.p+"static/media/gurel.125e8bab.jpg"},239:function(e,t,a){e.exports=a.p+"static/media/nina.aa412a0f.jpg"},240:function(e,t,a){e.exports=a.p+"static/media/vikram.384bb195.jpg"},241:function(e,t,a){e.exports=a.p+"static/media/vasco.ee3f4fd1.png"},265:function(e,t,a){e.exports=a(506)},270:function(e,t,a){},506:function(e,t,a){"use strict";a.r(t);var n=a(13),r=a(1),o=a.n(r),s=a(11),l=a.n(s),i=(a(270),a(54),a(140)),c=a(41),m=a(42),d=a(45),p=a(44),u=a(19),h=a(17),f=a(108);function E(){var e=Object(u.a)(["\n  display: inline-block;\n  margin-right: 0.75rem;\n  margin-bottom: 0.75rem;\n  padding: 0.5rem 1rem;\n  background-color: ",";\n  color: ",";\n  border: 3px solid ",";\n  border-radius: 2px;\n  font-weight: bold;\n"]);return E=function(){return e},e}function v(){var e=Object(u.a)(["\n  white-space: pre-wrap;\n"]);return v=function(){return e},e}function b(){var e=Object(u.a)(["\n  margin-top: 1.5rem;\n  margin-bottom: 0.5rem;\n"]);return b=function(){return e},e}h.a.h3(b()),h.a.p(v()),h.a.span(E(),f.a[20],f.a[70],f.a[70]);var w=a(141),g=a.n(w);function y(){var e=Object(u.a)(["\n  &.page-enter {\n    animation: "," 0.2s forwards;\n  }\n  &.page-exit {\n    animation: "," 0.2s forwards;\n  }\n"]);return y=function(){return e},e}function j(){var e=Object(u.a)(['\nposition: relative;\nwidth: 100vw;\nheight: 100vh;\nbackground-color: #283040;\nfont-family: "Open Sans", sans-serif;\nfont-align:center;\n\n']);return j=function(){return e},e}function O(){var e=Object(u.a)(["\n  from {\n    -webkit-transform: translate3d(0, 0, 0);\n    transform: translate3d(0, 0, 0);\n  }\n\n  to {\n    visibility: hidden;\n    -webkit-transform: translate3d(-100%, 0, 0);\n    transform: translate3d(-100%, 0, 0);\n  }\n"]);return O=function(){return e},e}function k(){var e=Object(u.a)(["\n  from {\n    -webkit-transform: translate3d(-100%, 0, 0);\n    transform: translate3d(-100%, 0, 0);\n    visibility: visible;\n  }\n\n  to {\n    -webkit-transform: translate3d(0, 0, 0);\n    transform: translate3d(0, 0, 0);\n  }\n"]);return k=function(){return e},e}var x=Object(h.b)(k()),_=Object(h.b)(O()),N=h.a.div(j()),T=Object(h.a)(N)(y(),x,_),S=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(m.a)(a,[{key:"render",value:function(){return o.a.createElement("div",{className:"home"},o.a.createElement(N,null,o.a.createElement(T,null,o.a.createElement(g.a,{className:"MyTypist"},"This is a  ",o.a.createElement("span",{className:"name"},"Human-computer interaction project"),". A real-time Hand Gesture Recognition system.",o.a.createElement(g.a.Delay,{ms:5e3})),o.a.createElement("div",{id:"arrowAnim"},o.a.createElement(n.b,{to:"/about"},o.a.createElement("div",{class:"arrowSliding"},o.a.createElement("div",{class:"arrow"})),"  "),o.a.createElement(n.b,{to:"/about"},o.a.createElement("div",{class:"arrowSliding delay1"},o.a.createElement("div",{class:"arrow"}))),o.a.createElement(n.b,{to:"/about"},o.a.createElement("div",{class:"arrowSliding delay2"},o.a.createElement("div",{class:"arrow"}))),o.a.createElement(n.b,{to:"/about"},o.a.createElement("div",{class:"arrowSliding delay3"},o.a.createElement("div",{class:"arrow"})))))))}}]),a}(r.Component),C=a(43),M=a.n(C);function A(){var e=Object(u.a)(["\n  // display: grid;\n  // grid-gap: 10px;\n  // margin-top: 1em;\n  // margin-left: 6em;\n  // margin-right: 6em;\n  // grid-template-columns: repeat(12, 1fr);\n  // grid-auto-rows: minmax(25px, auto);\n"]);return A=function(){return e},e}var P=h.a.div(A()),D=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(m.a)(a,[{key:"render",value:function(){return o.a.createElement(P,null,o.a.createElement("link",{rel:"stylesheet",href:"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"}),o.a.createElement("nav",{className:"Navbar"},o.a.createElement("div",{className:"Nav__container"},o.a.createElement("div",{className:"Nav__right"},o.a.createElement("ul",{className:"Nav__item-wrapper"},o.a.createElement("li",{className:"Nav__item"},o.a.createElement(n.b,{className:"Nav__link",to:"/"},"Home")),o.a.createElement("li",{className:"Nav__item"},o.a.createElement(n.b,{className:"Nav__link ",to:"/About"},"About")),o.a.createElement("li",{className:"Nav__item"},o.a.createElement(n.b,{className:"Nav__link ",to:"/DataCollection"},"Data Collection")),o.a.createElement("li",{className:"Nav__item"},o.a.createElement(n.b,{className:"Nav__link",to:"/Machine Learning"},"Machine Learning")),o.a.createElement("li",{className:"Nav__item"},o.a.createElement(n.b,{className:"Nav__link",to:"/The Team"},"The Team")),o.a.createElement("li",{className:"Nav__item"},o.a.createElement(n.b,{className:"Nav__link",to:"/Division of Work"},"Future Prospects")),o.a.createElement("li",{className:"Nav__item"},o.a.createElement(n.b,{className:"Nav__link",to:"/References"},"References")))))))}}]),a}(o.a.Component);a(65);function R(){var e=Object(u.a)(['\nbackground-color: #e3f2fd;\nfont-family: "Open Sans", sans-serif;\n\n']);return R=function(){return e},e}var q=h.a.div(R()),G=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(m.a)(a,[{key:"render",value:function(){return o.a.createElement(q,null,o.a.createElement("link",{rel:"stylesheet",href:"https://www.w3schools.com/w3css/4/w3.css"}),o.a.createElement("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),o.a.createElement("script",{src:"https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"}),o.a.createElement("script",{src:"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"}),o.a.createElement("script",{src:"https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"}),o.a.createElement(D,{fixed:"top"}),o.a.createElement(M.a,{left:!0},o.a.createElement("h2",{className:"title_abou"},"About")),o.a.createElement("p",{class:"container"},"The inspiration for this project was the movie \u201cMinority Report\u201d, specifically the scene where Tom Cruise is using hand gestures to control the display. Based on the output from tutorial 1 we know the sensor can tell XYZ dimensions/directions, which means that technically we can capture most of the movements of the mouse. We are going to reuse parts of the code from tutorial 1 and modify it to create and open a port to submit data as we move the sensor. More clearly, it\u2019ll be passing the data to a python script. There is a package in python called \u201cPYAUTOGUI\u201d that allows you to control the position of the mouse, which means that once the python application receives the information it can identify changes in the data and correlate those to the mouse position. We will try and capture different movements for the mouse. We will try to at the minimum replicate all the movement classes that the PYAUTOGUI package captures. This pipeline will allow you to transfer the information from the sensor to something that can control the position of the mouse. The motivation for this project is that you can integrate this with any device or display so instead of having to manually select options you can do so via gestures, in other words touch might be augmented or substituted by motion. It could later on be modified to work for people with disabilities or ones who have suffered an injury to their fingers or arms, and allow them to use this as a headband (or similar device) to control the mouse/cursor\u2019s movement. Additionally, this would also be a better option for interaction in a VR or AR world."),o.a.createElement("footer",{class:"contact-footer"},o.a.createElement("div",{class:"social"}),o.a.createElement("br",null),o.a.createElement("span",{class:"credit"},o.a.createElement("span",{class:"Copyright"},"\xa92020 Copyright")," ",o.a.createElement("span",{class:"footername"}))))}}]),a}(r.Component),W=(a(324),a(235)),F=a.n(W);function L(){var e=Object(u.a)(['\nbackground-color: #e3f2fd;\nfont-family: "Open Sans", sans-serif;\n\n']);return L=function(){return e},e}var B=h.a.div(L()),I=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(m.a)(a,[{key:"render",value:function(){return o.a.createElement(B,null,o.a.createElement("link",{rel:"stylesheet",href:"https://www.w3schools.com/w3css/4/w3.css"}),o.a.createElement("link",{rel:"stylesheet",href:"/css/video-react.css"}),o.a.createElement("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),o.a.createElement("script",{src:"https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"}),o.a.createElement("script",{src:"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"}),o.a.createElement("script",{src:"https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"}),o.a.createElement(D,{fixed:"top"}),o.a.createElement(M.a,{left:!0},o.a.createElement("h2",{className:"title_abou"},"Data Collection")),o.a.createElement("p",{class:"container"},"To collect the data, we first had to investigate the \u201cPYAUTOGUI\u201d package to determine the movements and get an idea of how we could compile the code. After some investigation, we decided to use 6 motions, each mapped to a certain movement of the mouse or a click. The movements we chose to collect data on include right swipe, left swipe, upward swipe, downward swipe, spiral, and wave. The swiping movements are used to control the mouse and which direction it will go as we move the sensor, and the spiral and wave gestures are used to imitate the right and left clicks of the mouse. After agreeing on the types of motions, we proceeded with the data collection. For each movement, we decided it would be best to use 75% of the data for training and 25% of the data for testing. To do that, we decided to collect data 30 times for each of the gestures, totaling 180 collections. To add variety to our gestures, we decided to use different speeds for the movements: fast, medium, and slow. These little differences were used to create a real-world-model to accommodate for different users and different speeds. After collecting each data, we labeled them according to their speeds and their types. Finally, we uploaded them to our GitHub repository to proceed with data processing."),o.a.createElement("div",{style:{position:"absolute",left:"50%",top:"65%",transform:"translate(-50%, -50%)"}},o.a.createElement(F.a,{url:"https://youtu.be/8kh1hSd1tag"})),o.a.createElement("footer",{class:"contact-footer"},o.a.createElement("div",{class:"social"}),o.a.createElement("br",null),o.a.createElement("span",{class:"credit"},o.a.createElement("span",{class:"Copyright"},"\xa92020 Copyright")," ",o.a.createElement("span",{class:"footername"}))))}}]),a}(r.Component),z=(a(362),a(377),a(378),a(237)),U=a.n(z),V=a(238),H=a.n(V),X=a(239),Y=a.n(X),J=a(240),Z=a.n(J),K=a(241),$=a.n(K),Q=a(544),ee=a(542),te=a(543),ae=a(540),ne=a(538),re=a(539),oe=a(109);a(507);function se(){var e=Object(u.a)(['\nbackground-color: #e3f2fd;\nfont-family: "Open Sans", sans-serif;\n']);return se=function(){return e},e}var le=h.a.div(se()),ie=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(m.a)(a,[{key:"render",value:function(){return o.a.createElement(le,null,o.a.createElement("link",{rel:"stylesheet",href:"https://www.w3schools.com/w3css/4/w3.css"}),o.a.createElement("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),o.a.createElement("script",{src:"https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"}),o.a.createElement("script",{src:"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"}),o.a.createElement("script",{src:"https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"}),o.a.createElement(D,{fixed:"top"}),o.a.createElement(M.a,{left:!0},o.a.createElement("h2",null,"Our amazing team")),o.a.createElement("div",{class:"topContainer"},o.a.createElement(Q.a,{horizontal:!0},o.a.createElement(te.a,null,o.a.createElement(ne.a,{primary:"Hidai Bar-mor (hidai25@gmail.com)",secondary:o.a.createElement(o.a.Fragment,null,o.a.createElement(oe.a,{component:"span",variant:"body2",color:"textPrimary"})," Hidai did the the data collection ,real time python script, github management and web development of the website of the project")}),o.a.createElement(re.a,{class:"avatar"},o.a.createElement(ee.a,{avatar:!0,src:U.a}))),o.a.createElement(ae.a,null),o.a.createElement(te.a,null,o.a.createElement(ne.a,{primary:"Gurel Ari (gurelari.ivy@gmail.com)",secondary:o.a.createElement(o.a.Fragment,null,o.a.createElement(oe.a,{component:"span",variant:"body2",color:"textPrimary"})," \tGurel did the data collection for the project and helped writing the final report")}),o.a.createElement(re.a,{class:"avatar"},o.a.createElement(ee.a,{avatar:!0,src:H.a}))),o.a.createElement(ae.a,null),o.a.createElement(te.a,null,o.a.createElement(ne.a,{primary:"Nina Tabari ( naz706@g.harvard.edu)",secondary:o.a.createElement(o.a.Fragment,null,o.a.createElement(oe.a,{component:"span",variant:"body2",color:"textPrimary"}),"\tNina did the python script to deploy and run the machine learning model in production and the wrote the reports")}),o.a.createElement(re.a,{class:"avatar"},o.a.createElement(ee.a,{avatar:!0,src:Y.a}))),o.a.createElement(ae.a,null),o.a.createElement(te.a,null,o.a.createElement(ne.a,{primary:"Vikram Maduskar (vim882@g.harvard.edu)",secondary:o.a.createElement(o.a.Fragment,null,o.a.createElement(oe.a,{component:"span",variant:"body2",color:"textPrimary"})," \tVikram was reponsible for the machine learning part where he preprocessed the data build and ran the model")}),o.a.createElement(re.a,{class:"avatar"},o.a.createElement(ee.a,{avatar:!0,src:Z.a}))),o.a.createElement(ae.a,null),o.a.createElement(te.a,null,o.a.createElement(ne.a,{primary:"Vasco Meerman (vmeerman.appdev@gmail.com)",secondary:o.a.createElement(o.a.Fragment,null,o.a.createElement(oe.a,{component:"span",variant:"body2",color:"textPrimary"})," Vasco was reponsible for cleaning and preprocessing the data and helped with the implementation of the machine learnign model")}),o.a.createElement(re.a,{class:"avatar"},o.a.createElement(ee.a,{avatar:!0,src:$.a})))),o.a.createElement("footer",{class:"contact-footer"},o.a.createElement("div",{class:"social"}),o.a.createElement("br",null),o.a.createElement("span",{class:"credit"},o.a.createElement("span",{class:"Copyright"},"\xa92020 Copyright")," ",o.a.createElement("span",{class:"footername"})))))}}]),a}(o.a.Component);function ce(){var e=Object(u.a)(['\nbackground-color: #e3f2fd;\nfont-family: "Open Sans", sans-serif;\n\n']);return ce=function(){return e},e}var me=h.a.div(ce());var de=function(e){return o.a.createElement(me,null,o.a.createElement("link",{rel:"stylesheet",href:"https://www.w3schools.com/w3css/4/w3.css"}),o.a.createElement("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),o.a.createElement("script",{src:"https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"}),o.a.createElement("script",{src:"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"}),o.a.createElement("script",{src:"https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"}),o.a.createElement(D,{fixed:"top"}),o.a.createElement(M.a,{left:!0},o.a.createElement("h2",null,"Future Prospects")),o.a.createElement("div",{class:"container"}),o.a.createElement("footer",{class:"contact-footer"},o.a.createElement("div",{class:"social"}),o.a.createElement("br",null),o.a.createElement("span",{class:"credit"},o.a.createElement("span",{class:"Copyright"},"\xa92020 Copyright"))))};function pe(){var e=Object(u.a)(['\nbackground-color: #e3f2fd;\nfont-family: "Open Sans", sans-serif;\n']);return pe=function(){return e},e}var ue=h.a.div(pe()),he=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(m.a)(a,[{key:"render",value:function(){return o.a.createElement(ue,null,o.a.createElement("link",{rel:"stylesheet",href:"https://www.w3schools.com/w3css/4/w3.css"}),o.a.createElement("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),o.a.createElement("script",{src:"https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"}),o.a.createElement("script",{src:"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"}),o.a.createElement("script",{src:"https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"}),o.a.createElement(D,{fixed:"top"}),o.a.createElement("br",null),o.a.createElement("div",{class:"plate"},o.a.createElement(M.a,{left:!0},o.a.createElement("h2",{class:"script"},o.a.createElement("span",null,"Machine Learning")))),o.a.createElement("br",null),o.a.createElement("div",{class:"row"},o.a.createElement("div",{class:"col-sm-6"},o.a.createElement("div",{class:"skillstxt"})),o.a.createElement("div",{class:"col-sm-6"},o.a.createElement("div",{class:"skills"},o.a.createElement("h3",null," Overview"),"The project is focused on replicating the movements of a traditional mouse using a STM32 sensortile and a python package called PYAUTOGUI. The idea is that you can integrate a sensortile flashed with the appropriate embedded alogorithm and ML into any wearable device or display which instead of requiring the user to manually select options allows, enables control via gestures. Our POC can be extended further to enable people with permanent disabilities or those who have suffered an injury to their fingers or arms, to use this as a fingreband (or headband or a similar device) to control the mouse/cursor movement. Additionally, this can also be implemented for gesture driven interactions in a VR or AR world.",o.a.createElement("h3",null,"  Data Description"),"The dataset used for building the classification models was collected by creating and opening a data port mapping to the STM32 Sensortile hardware as we moved the sensor by hand. We have capture data fom the sensor's Accelaratometer, Magnetometer and Gyroscope6 along the X,Y and Z axis for 6 different hand gestures for the mouse:Up, Down,Left,Right,Spiral and Wave. We collected data for 15 sets for each movetype type in multiple csv files that were merged to create a single csv file. This file was then split into a training dataset csv file and a test dataset csv file.",o.a.createElement("h3",null,"  Our Methodology"),"Step 1. Environment Setup Step 2. Data Setup Step 3. Exploratory Data Analysis Step 4. Classifier Model Training & Evaluate Models Model 1:Logitisc Regression Model 2: SVM Model 3:Random Forest Model 4: AdaBoost Model 5: XGBoost Step 5. Model Selection Step 6. Hyper Parameter Tuning Of Selected Model Step 7. Save Persistent Finalized Model to Disk",o.a.createElement("h3",null,"5. BEST MODEL SELECTION"),"Based upon the above model performance statistics, we can observe that the XGBoost model at 90% accuracy, Precision between 84% to 95% and recall between 80% to 99% for the 6 classes. Comparing the model performancewith other models we observe that Model 5(XGBoost) easily outperforms the other models by a wide margin. The difference in performance is so large that there is no need to even consider an ensemble approach and going with XGBoost as the lone model will be the best approach in our case. Therefore, we select this model as the winner and try to tune in further and see if it imrpves further.",o.a.createElement("h4",null,"Model Tuning Result:"),"We see a massive improvement in the performance of our model! The accuracy has improved from 85% to aprox 98%. We see similar improvements in Precision and Recall as well.",o.a.createElement("h3",null," 7. SAVE PERSISTANT FINAL MODEL TO DISK"),"After training our model, it is desirable to have a way to persist the model for future use without having to retrain. Therefore, we save our trained and hypertuned model to the disk from where it can be re-loaded and used anytime to perform classifications for new input data. The model is stored in a serialized form and deserialized when re-loaded for use. We will use the joblib utility to create and save the seralized persistent model.This fully trained and persistent model is now fully ready to be deployed and invoked in a production environment and peform classification for new input data going forward."))),o.a.createElement("footer",{bottom:"\xa92020 Copyright"},o.a.createElement("div",{class:"social"}),o.a.createElement("br",null),o.a.createElement("span",null,"\xa92020 Copyright",o.a.createElement("span",{class:"footername"}))))}}]),a}(r.Component),fe=a(25),Ee=a(541);function ve(){var e=Object(u.a)(['\nbackground-color: #e3f2fd;\nfont-family: "Open Sans", sans-serif;\n\n']);return ve=function(){return e},e}var be=h.a.div(ve());var we=function(e){return o.a.createElement(be,null,o.a.createElement("link",{rel:"stylesheet",href:"https://www.w3schools.com/w3css/4/w3.css"}),o.a.createElement("meta",{name:"viewport",content:"width=device-width, initial-scale=1"}),o.a.createElement("script",{src:"https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"}),o.a.createElement("script",{src:"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"}),o.a.createElement("script",{src:"https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"}),o.a.createElement(D,{fixed:"top"}),o.a.createElement(M.a,{left:!0},o.a.createElement("h2",null,"References")),o.a.createElement("div",{class:"container"},o.a.createElement(Ee.a,{component:"nav","aria-label":"mailbox folders"},o.a.createElement(te.a,{button:!0}," 1.",o.a.createElement("a",{href:"https://machinelearningmastery.com/how-to-model-human-activity-from-smartphone-data"},"https://machinelearningmastery.com/how-to-model-human-activity-from-smartphone-data/")),o.a.createElement(ae.a,null),o.a.createElement(te.a,{button:!0,divider:!0},"2.",o.a.createElement("a",{href:"http://stanford.edu/class/ee267/Spring2018/report_adu_bran-melendez.pdf"},"http://stanford.edu/class/ee267/Spring2018/report_adu_bran-melendez.pdf"),o.a.createElement(ne.a,null)),o.a.createElement(te.a,{button:!0},"3.",o.a.createElement("a",{href:"https://lembergsolutions.com/blog/motion-gesture-detection-using-tensorflow-android"},"https://lembergsolutions.com/blog/motion-gesture-detection-using-tensorflow-android"),o.a.createElement(ne.a,{primary:"Trash"})),o.a.createElement(ae.a,{light:!0}))),o.a.createElement("footer",{class:"contact-footer"},o.a.createElement("div",{class:"social"}),o.a.createElement("br",null),o.a.createElement("span",{class:"credit"},o.a.createElement("span",{class:"Copyright"},"\xa92020 Copyright"))))},ge=function(){return o.a.createElement(fe.c,null,o.a.createElement(fe.a,{exact:!0,path:"/",component:S}),o.a.createElement(fe.a,{path:"/about",component:G}),o.a.createElement(fe.a,{path:"/DataCollection",component:I}),o.a.createElement(fe.a,{path:"/Machine Learning",component:he}),o.a.createElement(fe.a,{path:"/The team",component:ie}),o.a.createElement(fe.a,{path:"/Division of Work",component:de}),o.a.createElement(fe.a,{path:"/References",component:we}))};var ye=function(){return o.a.createElement("div",{className:"App"},o.a.createElement(i.Layout,null,o.a.createElement("head",null),o.a.createElement(i.Content,null,o.a.createElement(ge,null))))};a(504),a(505),Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));l.a.render(o.a.createElement(n.a,{basename:"/mouse_project_frontend"},o.a.createElement(ye,null)),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()}))},54:function(e,t,a){}},[[265,1,2]]]);
//# sourceMappingURL=main.c7270b56.chunk.js.map